{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87cdfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd857298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torchvision.transforms import transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from PIL import Image\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbd9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weights(counts, dampen = 2):\n",
    "    weights = []\n",
    "    for c in counts:\n",
    "        v = 1 / (c * sum([1 / v for v in counts]))\n",
    "        v = v ** (1 / dampen)\n",
    "        weights.append(v)\n",
    "        \n",
    "    # make weights add up to 1\n",
    "    weights = [w / sum(weights) for w in weights]  \n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_dir, mode):\n",
    "    json_files = list(data_dir.glob(\"*.json\"))\n",
    "    assert len(json_files) == 1\n",
    "    data = json.load(open(str(json_files[0]), 'rb'))\n",
    "    \n",
    "    # Build map of image_id to file_name.\n",
    "    id_to_filename = {o['id']: o['file_name'] for o in data['images']}\n",
    "    \n",
    "    # Build maps between category_id and pytorch_index.\n",
    "    category_id_to_index = {0: 0, 2: 1, 4: 2, 5: 3}\n",
    "    index_to_category_id = {v: k for k, v in category_id_to_index.items()} \n",
    "    \n",
    "    # Build list of data.\n",
    "    data = [\n",
    "        {\n",
    "            'file_name': data_dir / \"images\" / id_to_filename[o['image_id']],\n",
    "            'label': category_id_to_index[o['category_id']]\n",
    "        } \n",
    "        for o in data['annotations'] if o['category_id'] in\n",
    "        list(category_id_to_index.keys())\n",
    "    ]\n",
    "    \n",
    "    def _use(file_name, mode):\n",
    "        value = str(file_name.parent.parent)[-1]\n",
    "        if mode == 'train':\n",
    "            return int(value) in [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "        else:\n",
    "            return int(value) in [8, 9]\n",
    "        \n",
    "    # Validate the data exists.\n",
    "    data = [\n",
    "        o for o in data \n",
    "        if pathlib.Path(data_dir / \"images\" / o['file_name']).exists()\n",
    "        and _use(o['file_name'], mode)\n",
    "    ]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6de1ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = get_data(pathlib.Path(\"/home/harry/DATA/animal_data/channel-islands/\"), 'train')\n",
    "data_val = get_data(pathlib.Path(\"/home/harry/DATA/animal_data/channel-islands/\"), 'valid')\n",
    "print(len(data_train), len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3dd7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        \n",
    "        self.data = data\n",
    "        \n",
    "        # Transforms\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize((224, 224),interpolation=Image.NEAREST),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.data[idx]['file_name'])\n",
    "        transformed_image = self.transforms(image)        \n",
    "        label = torch.Tensor([self.data[idx]['label']]).long()\n",
    "        return transformed_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1547f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    \n",
    "    \n",
    "    def __init__(self, data_train, data_val):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data_train = data_train\n",
    "        self.data_val = data_val\n",
    "   \n",
    "        backbone = models.resnet50(pretrained=True)\n",
    "        num_filters = backbone.fc.in_features\n",
    "        layers = list(backbone.children())[:-1]\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "\n",
    "        _fc_layers = [\n",
    "            nn.Linear(2048, 256), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(256, 32),\n",
    "            nn.Linear(32, 4)\n",
    "        ]\n",
    "        self.fc = nn.Sequential(*_fc_layers)\n",
    "        \n",
    "        weights = torch.tensor(self._calc_loss_weights(self.data_train))\n",
    "        self.loss_function = nn.CrossEntropyLoss(weight=weights)\n",
    "        \n",
    "        self.accuracy = Accuracy(average='weighted', num_classes=4)    \n",
    "        \n",
    "        self.validation_prediction_list = []\n",
    "        self.validation_gt_list = []\n",
    "        \n",
    "    def _calc_loss_weights(self, data_train):\n",
    "        counts = [0, 0, 0, 0]\n",
    "        for d in data_train:\n",
    "            counts[int(d['label'])] += 1\n",
    "\n",
    "        weights = calc_weights(counts, dampen=2)\n",
    "\n",
    "        return weights\n",
    "    \n",
    "    def _calc_metrics(self, pred, gt):\n",
    "\n",
    "        gt = gt.long().cpu().detach().numpy()\n",
    "        pred = np.argmax(pred.cpu().detach().numpy(), axis=-1)\n",
    "\n",
    "        kwargs = {'average': 'weighted'}\n",
    "\n",
    "        f1 = f1_score(y_true=gt, y_pred=pred, **kwargs)\n",
    "        recall = recall_score(y_true=gt, y_pred=pred, **kwargs)\n",
    "        precision = precision_score(y_true=gt, y_pred=pred, **kwargs)\n",
    "        accuracy = accuracy_score(y_true=gt, y_pred=pred)\n",
    "\n",
    "        metrics = {\n",
    "            'f1': torch.tensor(f1, dtype=torch.float32, device=self.device),\n",
    "            'recall': torch.tensor(recall, dtype=torch.float32, device=self.device),\n",
    "            'precision': torch.tensor(precision, dtype=torch.float32, device=self.device),\n",
    "            'accuracy': torch.tensor(accuracy, dtype=torch.float32, device=self.device)\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.squeeze(-1).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        preds = self.forward(x)\n",
    "        loss = self.loss_function(preds, y.squeeze())\n",
    "        metrics = self._calc_metrics(pred=preds, gt=y.squeeze())\n",
    "        \n",
    "        self.log('loss', loss)\n",
    "        for k, v in metrics.items():\n",
    "            self.log(k, v)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        preds = self.forward(x)        \n",
    "        loss = self.loss_function(preds, y.squeeze())\n",
    "        \n",
    "        self.validation_prediction_list.append(preds)\n",
    "        self.validation_gt_list.append(y.squeeze())\n",
    "\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "\n",
    "        prediction_logits = torch.cat(self.validation_prediction_list, dim=0)\n",
    "        gt = torch.cat(self.validation_gt_list, dim=0)\n",
    "\n",
    "        metrics = self._calc_metrics(prediction_logits, gt)\n",
    "        for k, v in metrics.items():\n",
    "            self.log(f'val_{k}', v)\n",
    "    \n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        \n",
    "        train_ds = CustomImageDataset(self.data_train)        \n",
    "        return DataLoader(train_ds, batch_size=32, num_workers=4, shuffle=True)\n",
    "    \n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        \n",
    "        valid_ds = CustomImageDataset(self.data_val)        \n",
    "        return DataLoader(valid_ds, batch_size=32, num_workers=4)\n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c57a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(data_train, data_val)\n",
    "wandb_logger = WandbLogger(project=\"thea\")\n",
    "trainer = pl.Trainer(gpus=1, logger=wandb_logger)\n",
    "#trainer = pl.Trainer(gpus=1)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e73af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
